---

# ğŸ§° Taller: Jobs con Pentaho Data Integration

---

## ğŸ¯ Objetivo

Aprender a crear Jobs.
Usar lookup tables.
Usar homologaciones.
Realizar varias transformaciones para hacer el cargue definitivo.

---


## Configuracion

Para MAC: version pdi-ce-10.2.0.0-222.zip
https://pentaho.com/pentaho-developer-edition/#communityProducts

Abrir una terminal:
1. Usa Command+BarraEspaciadora.
2. Escribe Terminal

En la terminal
1. Cambiarse al directorio data-integration:  cd /Users/Estudiantes/Downloads/data-integration
2. Correr spoon.sh:  sh spoon.sh


Para WINDOWS: Configuracion Pentaho 9.4

Requiere Java 11 o superior.

Configura java 11
https://jdk.java.net/archive/

Descarga Pentaho 
Para windows version 9.4
https://hitachiedge1.jfrog.io/artifactory/pntpub-maven-release-cache/org/pentaho/di/pdi-ce/9.4.0.0-343/pdi-ce-9.4.0.0-343.zip
Extrae el contenido del zip.

Adiciona al comienzo  del archivo "set-pentaho-env.bat". Los XXX representan el path hasta el jdk 
set PENTAHO_JAVA_HOME="XXX\jdk-11.0.2"
set _PENTAHO_JAVA_HOME="XXX\jdk-11.0.2"




## ğŸ“ Archivo Origen

```csv
transaccion_id,Nombre_producto,Cantidad,Precio_unitario,total_pagado,metodo_pago,localizacion,fecha_transaccion
TXN_1961373,Coffee,2,2.0,4.0,Credit Card,Takeaway,2023-09-08
TXN_4977031,Cake,4,3.0,12.0,Cash,In-store,2023-05-16
TXN_4271903,Cookie,4,1.0,ERROR,Credit Card,In-store,2023-07-19
TXN_7034554,Salad,2,5.0,10.0,UNKNOWN,UNKNOWN,2023-04-27
TXN_3160411,Coffee,2,2.0,4.0,Digital Wallet,In-store,2023-06-11
TXN_2602893,Smoothie,5,4.0,20.0,Credit Card,,2023-03-31
TXN_4433211,UNKNOWN,3,3.0,9.0,ERROR,Takeaway,2023-10-06
TXN_6699534,Sandwich,4,4.0,16.0,Cash,UNKNOWN,2023-10-28
```

---

## ğŸ§± Tabla Destino: FACT_venta

```sql
CREATE TABLE FACT_venta (
	venta_id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,
	cliente_id INTEGER,
	producto_id INTEGER,
	tiempo_id NUMBER,
	cantidad REAL,
	valor_total REAL,
	canal_id INTEGER,
	metodo_id INTEGER,
	CONSTRAINT FACT_venta_DIM_cliente_FK FOREIGN KEY (cliente_id) REFERENCES DIM_cliente(cliente_id),
	CONSTRAINT FACT_venta_DIM_producto_FK FOREIGN KEY (producto_id) REFERENCES DIM_producto(producto_id),
	CONSTRAINT FACT_venta_DIM_tiempo_FK FOREIGN KEY (tiempo_id) REFERENCES DIM_tiempo(tiempo_id),
	CONSTRAINT FACT_venta_DIM_canal_FK FOREIGN KEY (canal_id) REFERENCES DIM_canal(canal_id),
	CONSTRAINT FACT_venta_DIM_metodo_FK FOREIGN KEY (metodo_id) REFERENCES DIM_metodo(metodo_id)
);

```

Configuracion de la base de datos en Pentaho:

Connection Name: SQLite_Connection
Connection Type: Generic database
Access: Native (JDBC)
Driver class name: org.sqlite.JDBC
URL: jdbc:sqlite:/ruta/completa/a/tu_base_de_datos.db


Ejemplo: jdbc:sqlite:/sf/etl/08/dwh.db


# ğŸ¯ Parte 1: Cargar los nombres de producto a la tabla DIM_productos

---

## ğŸ”§ Paso 1: Crear TransformaciÃ³n en Spoon

1. Abrir **Pentaho Spoon**.
2. Crear una nueva transformaciÃ³n (`.ktr`).
3. Agregar un paso **CSV File Input**:
   - Selecciona el archivo origen.
   - Define los campos y tipos:
     - `transaccion_id`: String
     - `Nombre_producto`: String
     - `Cantidad`: Number
     - `Precio_unitario`: Number
     - `total_pagado`: Number
     - `metodo_pago`: String
     - `localizacion`: String
     - `fecha_transaccion`: Date (`yyyy-MM-dd`)

---

## ğŸ§¼ Paso 2: Encontrar nombres de producto unicos

1. Usa **Select Values** para seleccionar la columna Nombre_producto.
2. Usa "Sort Rows" para ordenar la columna seleccionada.
3. Usa "Unique Rows" para dejar solo valores unicos.
4. Usa "Filter Rows" para dejar pasar los NO-NULL y utiliza "Dummy" para no hacer nada en caso que sea NULL

## ğŸ—ƒï¸ Paso 3: Enriquece la data de producto.

1. Agrega un paso **CSV File Input**:
   - Selecciona el archivo:   `skus.csv`.
   - Define los campos y tipos:
     - `nombre_producto`: String
     - `SKU`: String
2. Agrega un paso **Sort**:
   - Define los campos de ordenamiento:
     - `nombre_producto`: String
     

3. Agrega un paso **merge Join**  que una la salida del paso "Sort" y los registros unicos de Producto:
   - Define los campos de union:
     - `nombre_producto`: String
     - `nombre_producto`: String

4. Agrega un paso **Select Values**:
   - Define los campos:
     - `nombre_producto`: String
     - `precio_unitario: String
     - `SKU`: String
     
5. Agrega un paso **Database Lookup**:
  - Define la conexion a Sqlite:
    
  - Define los campos:
     - Lookup table: TRA_categoria
      Keys to lookup
     - TABLE FIELD: Nombre_original
     - Comparator: =
     - Field1: Nombre_producto
      Values to Return
     - FIELD: Nombre_traducido
     - New Name: categoria_id

6. Agrega un paso **Select Values**:
   - Define los campos:
     - `nombre_producto`: String
     - `precio_unitario: String
     - `SKU`: String
     - `categoria_id`: String

## ğŸ—ƒï¸ Paso 4: Carga en la Tabla DIM_producto
 

1. Agrega un paso **Insert/Update**:
  - Define la conexion a Sqlite:
    
  - Define los campos:
     - Lookup table: TRA_categoria
      Keys to lookup
     - TABLE FIELD: nombre
     - Comparator: =
     - Field1: Nombre_producto
      Update fields
     - nombre -> Nombre_traducido
     - valor_unitario -> Precio_unitario
     - sku -> sku
     - categoria_id -> categoria_id



---



# ğŸ¯ Parte 2: Crear una transformacion para cargue de la tabla FACT

---

## ğŸ”§ Paso 1: Crear TransformaciÃ³n en Spoon

1. Abrir **Pentaho Spoon**.
2. Crear una nueva transformaciÃ³n (`.ktr`).
3. Agregar un paso **CSV File Input**:
   - Selecciona el archivo origen.
   - Define los campos y tipos:
     - `transaccion_id`: String
     - `Nombre_producto`: String
     - `Cantidad`: Number
     - `Precio_unitario`: Number
     - `total_pagado`: Number
     - `metodo_pago`: String
     - `localizacion`: String
     - `fecha_transaccion`: Date (`yyyy-MM-dd`)

---


## ğŸ§¼ Paso 2: Limpieza de Datos

1. Agrega un paso **Replace in String**:
   -Reemplaza  `"ERROR"` por `"UNKNOWN"`.

2. Agrega un paso **Filter**:
   - Filtra donde los valores de total_pagado sean ERROR, UNKNOWN o NULL

---

## ğŸ”— Paso 3: Mapeo de Claves ForÃ¡neas

1. Agrega pasos **Stream Lookup** para buscar:
   - `producto_id` desde `DIM_producto` usando `Nombre_producto`.

2. Configura los campos de salida para poblar la tabla `FACT_venta`.

---

## ğŸ—ƒï¸ Paso 4: Carga en la Tabla FACT_venta

1. Agrega un paso **Table Output**:
   - Selecciona la tabla `FACT_venta`.
     specify database fields-
   - Mapea los campos:
     - `valor_total` â†’ `total_pagado`
     - `producto_id` â†’ `producto_id`
---

## ğŸ§ª Actividades Finales

1. Crea un Job que corra ambas transformaciones.
---
